Using TensorFlow backend.
2018-10-25 17:24:37,437 : INFO : training model in static mode
2018-10-25 17:24:37,437 : INFO : setting random seed to 123
2018-10-25 17:24:37,460 : INFO : loading and preprocessing dataset
2018-10-25 17:24:38,145 : INFO : training: 6557 samples, validation: 825 samples
2018-10-25 17:24:38,145 : INFO : using 16128 pos_tagged words
2018-10-25 17:24:38,145 : INFO : building embedding layer
2018-10-25 17:24:38,172 : INFO : loading projection weights from <zipfile.ZipExtFile name='model.txt' mode='r' compress_type=deflate>
2018-10-25 17:53:34,586 : INFO : loaded (2883863, 300) matrix from <zipfile.ZipExtFile [closed]>
2018-10-25 17:53:35,085 : WARNING : there are 9001 oov tokens
2018-10-25 17:53:38,893 : INFO : building model
2018-10-25 17:53:41.961358: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-10-25 17:53:41.962114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties: 
name: Tesla K20Xm major: 3 minor: 5 memoryClockRate(GHz): 0.732
pciBusID: 0000:84:00.0
totalMemory: 5.57GiB freeMemory: 5.49GiB
2018-10-25 17:53:41.962160: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0
2018-10-25 17:53:42.287501: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-10-25 17:53:42.287579: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 
2018-10-25 17:53:42.287595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N 
2018-10-25 17:53:42.287872: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5278 MB memory) -> physical GPU (device: 0, name: Tesla K20Xm, pci bus id: 0000:84:00.0, compute capability: 3.5)
2018-10-25 17:53:42,761 : INFO : training the model
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 50)           0                                            
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 50, 300)      4838700     input_1[0][0]                    
__________________________________________________________________________________________________
conv1d_1 (Conv1D)               (None, 48, 100)      90100       embedding_1[0][0]                
__________________________________________________________________________________________________
conv1d_2 (Conv1D)               (None, 47, 100)      120100      embedding_1[0][0]                
__________________________________________________________________________________________________
conv1d_3 (Conv1D)               (None, 46, 100)      150100      embedding_1[0][0]                
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 48, 100)      0           conv1d_1[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 47, 100)      0           conv1d_2[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 100)      0           conv1d_3[0][0]                   
__________________________________________________________________________________________________
global_max_pooling1d_1 (GlobalM (None, 100)          0           activation_1[0][0]               
__________________________________________________________________________________________________
global_max_pooling1d_2 (GlobalM (None, 100)          0           activation_2[0][0]               
__________________________________________________________________________________________________
global_max_pooling1d_3 (GlobalM (None, 100)          0           activation_3[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 300)          0           global_max_pooling1d_1[0][0]     
                                                                 global_max_pooling1d_2[0][0]     
                                                                 global_max_pooling1d_3[0][0]     
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 300)          0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 2)            602         dropout_1[0][0]                  
==================================================================================================
Total params: 5,199,602
Trainable params: 360,902
Non-trainable params: 4,838,700
__________________________________________________________________________________________________
Train on 6557 samples, validate on 825 samples
Epoch 1/30

 256/6557 [>.............................] - ETA: 58s - loss: 1.4557 - acc: 0.4883
 768/6557 [==>...........................] - ETA: 18s - loss: 1.6651 - acc: 0.5026
1280/6557 [====>.........................] - ETA: 10s - loss: 2.0922 - acc: 0.4977
1792/6557 [=======>......................] - ETA: 6s - loss: 2.1053 - acc: 0.5045 
2304/6557 [=========>....................] - ETA: 4s - loss: 2.0864 - acc: 0.5017
2816/6557 [===========>..................] - ETA: 3s - loss: 2.0441 - acc: 0.5046
3328/6557 [==============>...............] - ETA: 2s - loss: 1.9477 - acc: 0.5123
3840/6557 [================>.............] - ETA: 1s - loss: 1.8845 - acc: 0.5120
4352/6557 [==================>...........] - ETA: 1s - loss: 1.8295 - acc: 0.5115
4864/6557 [=====================>........] - ETA: 0s - loss: 1.8155 - acc: 0.5125
5376/6557 [=======================>......] - ETA: 0s - loss: 1.7606 - acc: 0.5182
5888/6557 [=========================>....] - ETA: 0s - loss: 1.7191 - acc: 0.5214
6400/6557 [============================>.] - ETA: 0s - loss: 1.6997 - acc: 0.5238
6557/6557 [==============================] - 4s 594us/step - loss: 1.6973 - acc: 0.5222 - val_loss: 1.2298 - val_acc: 0.5309
Epoch 2/30

 256/6557 [>.............................] - ETA: 0s - loss: 1.4902 - acc: 0.5469
 768/6557 [==>...........................] - ETA: 0s - loss: 1.3047 - acc: 0.5612
1280/6557 [====>.........................] - ETA: 0s - loss: 1.1979 - acc: 0.5727
1792/6557 [=======>......................] - ETA: 0s - loss: 1.1711 - acc: 0.5725
2304/6557 [=========>....................] - ETA: 0s - loss: 1.1238 - acc: 0.5803
2816/6557 [===========>..................] - ETA: 0s - loss: 1.0981 - acc: 0.5817
3328/6557 [==============>...............] - ETA: 0s - loss: 1.0928 - acc: 0.5808
3840/6557 [================>.............] - ETA: 0s - loss: 1.1091 - acc: 0.5805
4352/6557 [==================>...........] - ETA: 0s - loss: 1.0997 - acc: 0.5790
4864/6557 [=====================>........] - ETA: 0s - loss: 1.0866 - acc: 0.5849
5376/6557 [=======================>......] - ETA: 0s - loss: 1.0792 - acc: 0.5852
5888/6557 [=========================>....] - ETA: 0s - loss: 1.0675 - acc: 0.5880
6400/6557 [============================>.] - ETA: 0s - loss: 1.0647 - acc: 0.5875
6557/6557 [==============================] - 1s 107us/step - loss: 1.0584 - acc: 0.5888 - val_loss: 0.6762 - val_acc: 0.6242
Epoch 3/30

 256/6557 [>.............................] - ETA: 0s - loss: 0.8358 - acc: 0.6445
 768/6557 [==>...........................] - ETA: 0s - loss: 0.8389 - acc: 0.6393
1280/6557 [====>.........................] - ETA: 0s - loss: 0.7889 - acc: 0.6516
1792/6557 [=======>......................] - ETA: 0s - loss: 0.7784 - acc: 0.6590
2304/6557 [=========>....................] - ETA: 0s - loss: 0.8032 - acc: 0.6515
2816/6557 [===========>..................] - ETA: 0s - loss: 0.8182 - acc: 0.6424
3328/6557 [==============>...............] - ETA: 0s - loss: 0.8163 - acc: 0.6397
3840/6557 [================>.............] - ETA: 0s - loss: 0.8183 - acc: 0.6367
4608/6557 [====================>.........] - ETA: 0s - loss: 0.8126 - acc: 0.6398
5120/6557 [======================>.......] - ETA: 0s - loss: 0.8101 - acc: 0.6379
5632/6557 [========================>.....] - ETA: 0s - loss: 0.8114 - acc: 0.6385
6144/6557 [===========================>..] - ETA: 0s - loss: 0.8102 - acc: 0.6395
6557/6557 [==============================] - 1s 106us/step - loss: 0.8121 - acc: 0.6386 - val_loss: 0.6908 - val_acc: 0.6255
Epoch 4/30

 256/6557 [>.............................] - ETA: 0s - loss: 0.7820 - acc: 0.6289
 768/6557 [==>...........................] - ETA: 0s - loss: 0.6890 - acc: 0.6836
1280/6557 [====>.........................] - ETA: 0s - loss: 0.7049 - acc: 0.6852
1792/6557 [=======>......................] - ETA: 0s - loss: 0.7211 - acc: 0.6797
2304/6557 [=========>....................] - ETA: 0s - loss: 0.7117 - acc: 0.6819
2816/6557 [===========>..................] - ETA: 0s - loss: 0.7113 - acc: 0.6854
3328/6557 [==============>...............] - ETA: 0s - loss: 0.7098 - acc: 0.6830
3840/6557 [================>.............] - ETA: 0s - loss: 0.7079 - acc: 0.6836
4352/6557 [==================>...........] - ETA: 0s - loss: 0.7133 - acc: 0.6799
4864/6557 [=====================>........] - ETA: 0s - loss: 0.7236 - acc: 0.6756
5376/6557 [=======================>......] - ETA: 0s - loss: 0.7344 - acc: 0.6722
5888/6557 [=========================>....] - ETA: 0s - loss: 0.7257 - acc: 0.6754
6400/6557 [============================>.] - ETA: 0s - loss: 0.7235 - acc: 0.6777
6557/6557 [==============================] - 1s 107us/step - loss: 0.7202 - acc: 0.6782 - val_loss: 0.6411 - val_acc: 0.6388
Epoch 5/30

 256/6557 [>.............................] - ETA: 0s - loss: 0.6898 - acc: 0.6797
 768/6557 [==>...........................] - ETA: 0s - loss: 0.5827 - acc: 0.7331
1280/6557 [====>.........................] - ETA: 0s - loss: 0.6205 - acc: 0.7086
1792/6557 [=======>......................] - ETA: 0s - loss: 0.6191 - acc: 0.7126
2304/6557 [=========>....................] - ETA: 0s - loss: 0.6104 - acc: 0.7157
2816/6557 [===========>..................] - ETA: 0s - loss: 0.6051 - acc: 0.7163
3328/6557 [==============>...............] - ETA: 0s - loss: 0.6184 - acc: 0.7088
3840/6557 [================>.............] - ETA: 0s - loss: 0.6239 - acc: 0.7073
4352/6557 [==================>...........] - ETA: 0s - loss: 0.6254 - acc: 0.7057
4864/6557 [=====================>........] - ETA: 0s - loss: 0.6277 - acc: 0.7060
5376/6557 [=======================>......] - ETA: 0s - loss: 0.6336 - acc: 0.7039
5888/6557 [=========================>....] - ETA: 0s - loss: 0.6303 - acc: 0.7041
6400/6557 [============================>.] - ETA: 0s - loss: 0.6271 - acc: 0.7056
6557/6557 [==============================] - 1s 109us/step - loss: 0.6255 - acc: 0.7060 - val_loss: 0.6327 - val_acc: 0.6606
Epoch 6/30

 256/6557 [>.............................] - ETA: 0s - loss: 0.4971 - acc: 0.7617
 768/6557 [==>...........................] - ETA: 0s - loss: 0.5537 - acc: 0.7474
1280/6557 [====>.........................] - ETA: 0s - loss: 0.5589 - acc: 0.7438
1792/6557 [=======>......................] - ETA: 0s - loss: 0.5598 - acc: 0.7433
2304/6557 [=========>....................] - ETA: 0s - loss: 0.5511 - acc: 0.7487
2816/6557 [===========>..................] - ETA: 0s - loss: 0.5520 - acc: 0.7472
3328/6557 [==============>...............] - ETA: 0s - loss: 0.5540 - acc: 0.7470
3840/6557 [================>.............] - ETA: 0s - loss: 0.5489 - acc: 0.7484
4352/6557 [==================>...........] - ETA: 0s - loss: 0.5540 - acc: 0.7466
4864/6557 [=====================>........] - ETA: 0s - loss: 0.5567 - acc: 0.7451
5376/6557 [=======================>......] - ETA: 0s - loss: 0.5616 - acc: 0.7426
5888/6557 [=========================>....] - ETA: 0s - loss: 0.5632 - acc: 0.7405
6400/6557 [============================>.] - ETA: 0s - loss: 0.5606 - acc: 0.7422
6557/6557 [==============================] - 1s 108us/step - loss: 0.5603 - acc: 0.7424 - val_loss: 0.6350 - val_acc: 0.6473
Epoch 7/30

 256/6557 [>.............................] - ETA: 0s - loss: 0.5205 - acc: 0.7422
 768/6557 [==>...........................] - ETA: 0s - loss: 0.4724 - acc: 0.7682
1280/6557 [====>.........................] - ETA: 0s - loss: 0.4811 - acc: 0.7633
1792/6557 [=======>......................] - ETA: 0s - loss: 0.4830 - acc: 0.7662
2304/6557 [=========>....................] - ETA: 0s - loss: 0.4957 - acc: 0.7604
2816/6557 [===========>..................] - ETA: 0s - loss: 0.5049 - acc: 0.7546
3328/6557 [==============>...............] - ETA: 0s - loss: 0.5006 - acc: 0.7614
3840/6557 [================>.............] - ETA: 0s - loss: 0.4987 - acc: 0.7651
4352/6557 [==================>...........] - ETA: 0s - loss: 0.5029 - acc: 0.7629
4864/6557 [=====================>........] - ETA: 0s - loss: 0.5040 - acc: 0.7627
5376/6557 [=======================>......] - ETA: 0s - loss: 0.5046 - acc: 0.7608
5888/6557 [=========================>....] - ETA: 0s - loss: 0.5050 - acc: 0.7615
6400/6557 [============================>.] - ETA: 0s - loss: 0.5075 - acc: 0.7598
6557/6557 [==============================] - 1s 107us/step - loss: 0.5059 - acc: 0.7593 - val_loss: 0.6154 - val_acc: 0.6667
Epoch 8/30

 256/6557 [>.............................] - ETA: 0s - loss: 0.4116 - acc: 0.8242
 768/6557 [==>...........................] - ETA: 0s - loss: 0.4046 - acc: 0.8060
1280/6557 [====>.........................] - ETA: 0s - loss: 0.4139 - acc: 0.8086
1792/6557 [=======>......................] - ETA: 0s - loss: 0.4205 - acc: 0.8058
2304/6557 [=========>....................] - ETA: 0s - loss: 0.4313 - acc: 0.7986
2816/6557 [===========>..................] - ETA: 0s - loss: 0.4422 - acc: 0.7933
3328/6557 [==============>...............] - ETA: 0s - loss: 0.4522 - acc: 0.7888
3840/6557 [================>.............] - ETA: 0s - loss: 0.4532 - acc: 0.7888
4352/6557 [==================>...........] - ETA: 0s - loss: 0.4517 - acc: 0.7900
4864/6557 [=====================>........] - ETA: 0s - loss: 0.4525 - acc: 0.7895
5376/6557 [=======================>......] - ETA: 0s - loss: 0.4582 - acc: 0.7870
5888/6557 [=========================>....] - ETA: 0s - loss: 0.4629 - acc: 0.7833
6400/6557 [============================>.] - ETA: 0s - loss: 0.4610 - acc: 0.7842
6557/6557 [==============================] - 1s 109us/step - loss: 0.4588 - acc: 0.7854 - val_loss: 0.6125 - val_acc: 0.6715
Epoch 9/30

 256/6557 [>.............................] - ETA: 0s - loss: 0.3787 - acc: 0.8359
 768/6557 [==>...........................] - ETA: 0s - loss: 0.3695 - acc: 0.8346
1280/6557 [====>.........................] - ETA: 0s - loss: 0.3919 - acc: 0.8219
1792/6557 [=======>......................] - ETA: 0s - loss: 0.3946 - acc: 0.8203
2304/6557 [=========>....................] - ETA: 0s - loss: 0.3997 - acc: 0.8190
2816/6557 [===========>..................] - ETA: 0s - loss: 0.4140 - acc: 0.8093
3328/6557 [==============>...............] - ETA: 0s - loss: 0.4189 - acc: 0.8071
3840/6557 [================>.............] - ETA: 0s - loss: 0.4168 - acc: 0.8078
4352/6557 [==================>...........] - ETA: 0s - loss: 0.4209 - acc: 0.8072
4864/6557 [=====================>........] - ETA: 0s - loss: 0.4240 - acc: 0.8057
5376/6557 [=======================>......] - ETA: 0s - loss: 0.4309 - acc: 0.8004
5888/6557 [=========================>....] - ETA: 0s - loss: 0.4377 - acc: 0.7959
6400/6557 [============================>.] - ETA: 0s - loss: 0.4339 - acc: 0.7992
6557/6557 [==============================] - 1s 107us/step - loss: 0.4344 - acc: 0.7991 - val_loss: 0.5980 - val_acc: 0.6764
Epoch 10/30

 256/6557 [>.............................] - ETA: 0s - loss: 0.3109 - acc: 0.8711
 768/6557 [==>...........................] - ETA: 0s - loss: 0.3911 - acc: 0.8216
1280/6557 [====>.........................] - ETA: 0s - loss: 0.4067 - acc: 0.8148
1792/6557 [=======>......................] - ETA: 0s - loss: 0.3972 - acc: 0.8192
2304/6557 [=========>....................] - ETA: 0s - loss: 0.3884 - acc: 0.8251
2816/6557 [===========>..................] - ETA: 0s - loss: 0.3892 - acc: 0.8217
3328/6557 [==============>...............] - ETA: 0s - loss: 0.3953 - acc: 0.8182
3840/6557 [================>.............] - ETA: 0s - loss: 0.4133 - acc: 0.8117
4352/6557 [==================>...........] - ETA: 0s - loss: 0.4246 - acc: 0.8061
4864/6557 [=====================>........] - ETA: 0s - loss: 0.4295 - acc: 0.8026
5376/6557 [=======================>......] - ETA: 0s - loss: 0.4296 - acc: 0.8019
5888/6557 [=========================>....] - ETA: 0s - loss: 0.4238 - acc: 0.8047
6400/6557 [============================>.] - ETA: 0s - loss: 0.4187 - acc: 0.8063
6557/6557 [==============================] - 1s 107us/step - loss: 0.4223 - acc: 0.8040 - val_loss: 0.6305 - val_acc: 0.6509
Epoch 11/30

 256/6557 [>.............................] - ETA: 0s - loss: 0.3183 - acc: 0.8555
 768/6557 [==>...........................] - ETA: 0s - loss: 0.3465 - acc: 0.8398
1280/6557 [====>.........................] - ETA: 0s - loss: 0.3609 - acc: 0.8453
1792/6557 [=======>......................] - ETA: 0s - loss: 0.3577 - acc: 0.8438
2304/6557 [=========>....................] - ETA: 0s - loss: 0.3616 - acc: 0.8377
2816/6557 [===========>..................] - ETA: 0s - loss: 0.3630 - acc: 0.8391
3328/6557 [==============>...............] - ETA: 0s - loss: 0.3610 - acc: 0.8410
3840/6557 [================>.............] - ETA: 0s - loss: 0.3625 - acc: 0.8401
4352/6557 [==================>...........] - ETA: 0s - loss: 0.3593 - acc: 0.8442
4864/6557 [=====================>........] - ETA: 0s - loss: 0.3620 - acc: 0.8431
5376/6557 [=======================>......] - ETA: 0s - loss: 0.3565 - acc: 0.8447
5888/6557 [=========================>....] - ETA: 0s - loss: 0.3555 - acc: 0.8456
6400/6557 [============================>.] - ETA: 0s - loss: 0.3571 - acc: 0.8433
6557/6557 [==============================] - 1s 107us/step - loss: 0.3591 - acc: 0.8417 - val_loss: 0.6571 - val_acc: 0.6400
Epoch 12/30

 256/6557 [>.............................] - ETA: 0s - loss: 0.3859 - acc: 0.8438
 768/6557 [==>...........................] - ETA: 0s - loss: 0.3563 - acc: 0.8464
1280/6557 [====>.........................] - ETA: 0s - loss: 0.3500 - acc: 0.8523
1792/6557 [=======>......................] - ETA: 0s - loss: 0.3456 - acc: 0.8538
2304/6557 [=========>....................] - ETA: 0s - loss: 0.3346 - acc: 0.8559
2816/6557 [===========>..................] - ETA: 0s - loss: 0.3290 - acc: 0.8608
3328/6557 [==============>...............] - ETA: 0s - loss: 0.3289 - acc: 0.8624
3840/6557 [================>.............] - ETA: 0s - loss: 0.3274 - acc: 0.8625
4352/6557 [==================>...........] - ETA: 0s - loss: 0.3224 - acc: 0.8640
4864/6557 [=====================>........] - ETA: 0s - loss: 0.3191 - acc: 0.8651
5376/6557 [=======================>......] - ETA: 0s - loss: 0.3183 - acc: 0.8663
5888/6557 [=========================>....] - ETA: 0s - loss: 0.3194 - acc: 0.8658
6557/6557 [==============================] - 1s 107us/step - loss: 0.3161 - acc: 0.8673 - val_loss: 0.6052 - val_acc: 0.6861
Epoch 13/30

 256/6557 [>.............................] - ETA: 0s - loss: 0.2610 - acc: 0.8828
 768/6557 [==>...........................] - ETA: 0s - loss: 0.3016 - acc: 0.8789
1280/6557 [====>.........................] - ETA: 0s - loss: 0.3148 - acc: 0.8688
1792/6557 [=======>......................] - ETA: 0s - loss: 0.3049 - acc: 0.8733
2304/6557 [=========>....................] - ETA: 0s - loss: 0.3084 - acc: 0.8711
2816/6557 [===========>..................] - ETA: 0s - loss: 0.2986 - acc: 0.8757
3328/6557 [==============>...............] - ETA: 0s - loss: 0.3037 - acc: 0.8747
3840/6557 [================>.............] - ETA: 0s - loss: 0.3004 - acc: 0.8763
4352/6557 [==================>...........] - ETA: 0s - loss: 0.2980 - acc: 0.8768
4864/6557 [=====================>........] - ETA: 0s - loss: 0.2975 - acc: 0.8773
5376/6557 [=======================>......] - ETA: 0s - loss: 0.3010 - acc: 0.8743
5888/6557 [=========================>....] - ETA: 0s - loss: 0.3005 - acc: 0.8748
6400/6557 [============================>.] - ETA: 0s - loss: 0.3000 - acc: 0.8745
6557/6557 [==============================] - 1s 106us/step - loss: 0.2983 - acc: 0.8754 - val_loss: 0.6064 - val_acc: 0.6752
Epoch 14/30

 256/6557 [>.............................] - ETA: 0s - loss: 0.3320 - acc: 0.8320
 768/6557 [==>...........................] - ETA: 0s - loss: 0.2962 - acc: 0.8737
1280/6557 [====>.........................] - ETA: 0s - loss: 0.2983 - acc: 0.8773
1792/6557 [=======>......................] - ETA: 0s - loss: 0.2937 - acc: 0.8756
2304/6557 [=========>....................] - ETA: 0s - loss: 0.2901 - acc: 0.8785
2816/6557 [===========>..................] - ETA: 0s - loss: 0.2832 - acc: 0.8817
3328/6557 [==============>...............] - ETA: 0s - loss: 0.2868 - acc: 0.8801
3840/6557 [================>.............] - ETA: 0s - loss: 0.2895 - acc: 0.8786
4352/6557 [==================>...........] - ETA: 0s - loss: 0.2876 - acc: 0.8798
4864/6557 [=====================>........] - ETA: 0s - loss: 0.2885 - acc: 0.8783
5376/6557 [=======================>......] - ETA: 0s - loss: 0.2893 - acc: 0.8785
5888/6557 [=========================>....] - ETA: 0s - loss: 0.2865 - acc: 0.8791
6400/6557 [============================>.] - ETA: 0s - loss: 0.2869 - acc: 0.8784
6557/6557 [==============================] - 1s 108us/step - loss: 0.2876 - acc: 0.8783 - val_loss: 0.6054 - val_acc: 0.6800
2018-10-25 17:53:57,490 : INFO : loading best model weights
2018-10-25 17:53:58,051 : INFO : computing and saving metrics
             precision    recall  f1-score   support

   negative       0.65      0.73      0.69       408
   positive       0.70      0.62      0.66       417

avg / total       0.68      0.68      0.68       825

Using TensorFlow backend.
2018-10-25 17:54:05,589 : INFO : training model in static mode
2018-10-25 17:54:05,590 : INFO : setting random seed to 123
2018-10-25 17:54:05,611 : INFO : loading and preprocessing dataset
2018-10-25 17:54:06,506 : INFO : training: 6557 samples, validation: 825 samples
2018-10-25 17:54:06,506 : INFO : using 11324 lemmatized words
2018-10-25 17:54:06,506 : INFO : building embedding layer
2018-10-25 17:54:06,506 : INFO : loading Word2Vec object from /projects/nlpl/data/vectors/11/17.zip,
Traceback (most recent call last):
  File "train_model.py", line 146, in <module>
    emb = get_embedding(args.mode, args.word_vectors, tokenizer, args.max_len, emb_dim=args.emb_dim)
  File "train_model.py", line 73, in get_embedding
    emb_model = load_emb_model(path) if path else None
  File "/cluster/home/filipste/INF5820-Assignment3/emb.py", line 28, in load_emb_model
    return gensim.models.Word2Vec.load(embeddings_file)
  File "/projects/nlpl/software/inf5820/2018/lib/python3.5/site-packages/gensim/models/word2vec.py", line 1312, in load
    model = super(Word2Vec, cls).load(*args, **kwargs)
  File "/projects/nlpl/software/inf5820/2018/lib/python3.5/site-packages/gensim/models/base_any2vec.py", line 1244, in load
    model = super(BaseWordEmbeddingsModel, cls).load(*args, **kwargs)
  File "/projects/nlpl/software/inf5820/2018/lib/python3.5/site-packages/gensim/models/base_any2vec.py", line 603, in load
    return super(BaseAny2VecModel, cls).load(fname_or_handle, **kwargs)
  File "/projects/nlpl/software/inf5820/2018/lib/python3.5/site-packages/gensim/utils.py", line 422, in load
    obj = unpickle(fname)
  File "/projects/nlpl/software/inf5820/2018/lib/python3.5/site-packages/gensim/utils.py", line 1358, in unpickle
    with smart_open(fname, 'rb') as f:
  File "/projects/nlpl/software/tensorflow/1.11/lib/python3.5/site-packages/smart_open/smart_open_lib.py", line 181, in smart_open
    fobj = _shortcut_open(uri, mode, **kw)
  File "/projects/nlpl/software/tensorflow/1.11/lib/python3.5/site-packages/smart_open/smart_open_lib.py", line 301, in _shortcut_open
    return open(parsed_uri.uri_path, mode, buffering=buffering, **open_kwargs)
FileNotFoundError: [Errno 2] No such file or directory: '/projects/nlpl/data/vectors/11/17.zip,'
Using TensorFlow backend.
2018-10-25 17:54:10,936 : INFO : training model in static mode
2018-10-25 17:54:10,936 : INFO : setting random seed to 123
2018-10-25 17:54:10,953 : INFO : loading and preprocessing dataset
2018-10-25 17:54:11,834 : INFO : training: 6557 samples, validation: 825 samples
2018-10-25 17:54:11,834 : INFO : using 11324 lemmatized words
2018-10-25 17:54:11,834 : INFO : building embedding layer
2018-10-25 17:54:11,935 : INFO : loading projection weights from <zipfile.ZipExtFile name='model.txt' mode='r' compress_type=deflate>
2018-10-25 17:56:47,309 : INFO : loaded (260073, 300) matrix from <zipfile.ZipExtFile [closed]>
2018-10-25 17:56:47,674 : WARNING : there are 2373 oov tokens
2018-10-25 17:56:47,937 : INFO : building model
2018-10-25 17:56:51.091946: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-10-25 17:56:51.092700: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties: 
name: Tesla K20Xm major: 3 minor: 5 memoryClockRate(GHz): 0.732
pciBusID: 0000:84:00.0
totalMemory: 5.57GiB freeMemory: 5.49GiB
2018-10-25 17:56:51.092742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0
2018-10-25 17:56:51.505718: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-10-25 17:56:51.505799: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 
2018-10-25 17:56:51.505815: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N 
2018-10-25 17:56:51.506090: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5278 MB memory) -> physical GPU (device: 0, name: Tesla K20Xm, pci bus id: 0000:84:00.0, compute capability: 3.5)
2018-10-25 17:56:51,954 : INFO : training the model
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 50)           0                                            
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 50, 300)      3397500     input_1[0][0]                    
__________________________________________________________________________________________________
conv1d_1 (Conv1D)               (None, 48, 100)      90100       embedding_1[0][0]                
__________________________________________________________________________________________________
conv1d_2 (Conv1D)               (None, 47, 100)      120100      embedding_1[0][0]                
__________________________________________________________________________________________________
conv1d_3 (Conv1D)               (None, 46, 100)      150100      embedding_1[0][0]                
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 48, 100)      0           conv1d_1[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 47, 100)      0           conv1d_2[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 100)      0           conv1d_3[0][0]                   
__________________________________________________________________________________________________
global_max_pooling1d_1 (GlobalM (None, 100)          0           activation_1[0][0]               
__________________________________________________________________________________________________
global_max_pooling1d_2 (GlobalM (None, 100)          0           activation_2[0][0]               
__________________________________________________________________________________________________
global_max_pooling1d_3 (GlobalM (None, 100)          0           activation_3[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 300)          0           global_max_pooling1d_1[0][0]     
                                                                 global_max_pooling1d_2[0][0]     
                                                                 global_max_pooling1d_3[0][0]     
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 300)          0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 2)            602         dropout_1[0][0]                  
==================================================================================================
Total params: 3,758,402
Trainable params: 360,902
Non-trainable params: 3,397,500
__________________________________________________________________________________________________
Train on 6557 samples, validate on 825 samples
Epoch 1/30

 256/6557 [>.............................] - ETA: 1:15 - loss: 2.7228 - acc: 0.4688
 768/6557 [==>...........................] - ETA: 23s - loss: 1.9031 - acc: 0.5039 
1280/6557 [====>.........................] - ETA: 13s - loss: 1.8165 - acc: 0.5102
1792/6557 [=======>......................] - ETA: 8s - loss: 1.7977 - acc: 0.5201 
2304/6557 [=========>....................] - ETA: 6s - loss: 1.7226 - acc: 0.5269
2816/6557 [===========>..................] - ETA: 4s - loss: 1.7025 - acc: 0.5249
3328/6557 [==============>...............] - ETA: 3s - loss: 1.7271 - acc: 0.5249
3840/6557 [================>.............] - ETA: 2s - loss: 1.7060 - acc: 0.5336
4352/6557 [==================>...........] - ETA: 1s - loss: 1.6736 - acc: 0.5345
4864/6557 [=====================>........] - ETA: 1s - loss: 1.6436 - acc: 0.5387
5376/6557 [=======================>......] - ETA: 0s - loss: 1.6031 - acc: 0.5435
5888/6557 [=========================>....] - ETA: 0s - loss: 1.5676 - acc: 0.5486
6400/6557 [============================>.] - ETA: 0s - loss: 1.5422 - acc: 0.5497
6557/6557 [==============================] - 5s 707us/step - loss: 1.5336 - acc: 0.5512 - val_loss: 1.1493 - val_acc: 0.5636
Epoch 2/30

 256/6557 [>.............................] - ETA: 0s - loss: 1.4016 - acc: 0.5859
 768/6557 [==>...........................] - ETA: 0s - loss: 1.1623 - acc: 0.6055
1280/6557 [====>.........................] - ETA: 0s - loss: 1.1361 - acc: 0.6180
1792/6557 [=======>......................] - ETA: 0s - loss: 1.1011 - acc: 0.6205
2304/6557 [=========>....................] - ETA: 0s - loss: 1.0656 - acc: 0.6233
2816/6557 [===========>..................] - ETA: 0s - loss: 1.0220 - acc: 0.6328
3328/6557 [==============>...............] - ETA: 0s - loss: 1.0139 - acc: 0.6352
3840/6557 [================>.............] - ETA: 0s - loss: 0.9993 - acc: 0.6414
4352/6557 [==================>...........] - ETA: 0s - loss: 0.9836 - acc: 0.6432
4864/6557 [=====================>........] - ETA: 0s - loss: 0.9828 - acc: 0.6433
5376/6557 [=======================>......] - ETA: 0s - loss: 0.9778 - acc: 0.6466
5888/6557 [=========================>....] - ETA: 0s - loss: 0.9780 - acc: 0.6457
6400/6557 [============================>.] - ETA: 0s - loss: 0.9687 - acc: 0.6467
6557/6557 [==============================] - 1s 109us/step - loss: 0.9671 - acc: 0.6468 - val_loss: 0.6255 - val_acc: 0.6848
Epoch 3/30

 256/6557 [>.............................] - ETA: 0s - loss: 0.7684 - acc: 0.6719
 768/6557 [==>...........................] - ETA: 0s - loss: 0.7752 - acc: 0.6797
1280/6557 [====>.........................] - ETA: 0s - loss: 0.7508 - acc: 0.6914
1792/6557 [=======>......................] - ETA: 0s - loss: 0.7382 - acc: 0.6931
2304/6557 [=========>....................] - ETA: 0s - loss: 0.7493 - acc: 0.6927
2816/6557 [===========>..................] - ETA: 0s - loss: 0.7554 - acc: 0.6925
3328/6557 [==============>...............] - ETA: 0s - loss: 0.7583 - acc: 0.6896
3840/6557 [================>.............] - ETA: 0s - loss: 0.7534 - acc: 0.6898
4352/6557 [==================>...........] - ETA: 0s - loss: 0.7542 - acc: 0.6900
4864/6557 [=====================>........] - ETA: 0s - loss: 0.7581 - acc: 0.6883
5376/6557 [=======================>......] - ETA: 0s - loss: 0.7615 - acc: 0.6869
5888/6557 [=========================>....] - ETA: 0s - loss: 0.7596 - acc: 0.6887
6400/6557 [============================>.] - ETA: 0s - loss: 0.7553 - acc: 0.6905
6557/6557 [==============================] - 1s 106us/step - loss: 0.7545 - acc: 0.6901 - val_loss: 0.5576 - val_acc: 0.7273
Epoch 4/30

 256/6557 [>.............................] - ETA: 0s - loss: 0.5501 - acc: 0.7617
 768/6557 [==>...........................] - ETA: 0s - loss: 0.5661 - acc: 0.7578
1280/6557 [====>.........................] - ETA: 0s - loss: 0.6189 - acc: 0.7453
1792/6557 [=======>......................] - ETA: 0s - loss: 0.6545 - acc: 0.7327
2304/6557 [=========>....................] - ETA: 0s - loss: 0.6575 - acc: 0.7331
2816/6557 [===========>..................] - ETA: 0s - loss: 0.6612 - acc: 0.7330
3328/6557 [==============>...............] - ETA: 0s - loss: 0.6486 - acc: 0.7383
3840/6557 [================>.............] - ETA: 0s - loss: 0.6368 - acc: 0.7401
4352/6557 [==================>...........] - ETA: 0s - loss: 0.6382 - acc: 0.7376
4864/6557 [=====================>........] - ETA: 0s - loss: 0.6404 - acc: 0.7368
5376/6557 [=======================>......] - ETA: 0s - loss: 0.6341 - acc: 0.7375
5888/6557 [=========================>....] - ETA: 0s - loss: 0.6335 - acc: 0.7359
6400/6557 [============================>.] - ETA: 0s - loss: 0.6341 - acc: 0.7358
6557/6557 [==============================] - 1s 108us/step - loss: 0.6379 - acc: 0.7349 - val_loss: 0.6222 - val_acc: 0.6933
Epoch 5/30

 256/6557 [>.............................] - ETA: 0s - loss: 0.5206 - acc: 0.7812
 768/6557 [==>...........................] - ETA: 0s - loss: 0.5869 - acc: 0.7617
1280/6557 [====>.........................] - ETA: 0s - loss: 0.6183 - acc: 0.7492
1792/6557 [=======>......................] - ETA: 0s - loss: 0.6239 - acc: 0.7517
2304/6557 [=========>....................] - ETA: 0s - loss: 0.6245 - acc: 0.7457
2816/6557 [===========>..................] - ETA: 0s - loss: 0.6316 - acc: 0.7372
3328/6557 [==============>...............] - ETA: 0s - loss: 0.6083 - acc: 0.7467
3840/6557 [================>.............] - ETA: 0s - loss: 0.6042 - acc: 0.7500
4352/6557 [==================>...........] - ETA: 0s - loss: 0.5950 - acc: 0.7525
4864/6557 [=====================>........] - ETA: 0s - loss: 0.5872 - acc: 0.7549
5376/6557 [=======================>......] - ETA: 0s - loss: 0.5837 - acc: 0.7550
5888/6557 [=========================>....] - ETA: 0s - loss: 0.5789 - acc: 0.7565
6400/6557 [============================>.] - ETA: 0s - loss: 0.5789 - acc: 0.7558
6557/6557 [==============================] - 1s 107us/step - loss: 0.5780 - acc: 0.7557 - val_loss: 0.5303 - val_acc: 0.7503
Epoch 6/30

 256/6557 [>.............................] - ETA: 0s - loss: 0.4096 - acc: 0.8164
 768/6557 [==>...........................] - ETA: 0s - loss: 0.4713 - acc: 0.7852
1280/6557 [====>.........................] - ETA: 0s - loss: 0.5226 - acc: 0.7680
1792/6557 [=======>......................] - ETA: 0s - loss: 0.4814 - acc: 0.7868
2304/6557 [=========>....................] - ETA: 0s - loss: 0.4823 - acc: 0.7856
2816/6557 [===========>..................] - ETA: 0s - loss: 0.4753 - acc: 0.7891
3328/6557 [==============>...............] - ETA: 0s - loss: 0.4664 - acc: 0.7942
3840/6557 [================>.............] - ETA: 0s - loss: 0.4792 - acc: 0.7862
4352/6557 [==================>...........] - ETA: 0s - loss: 0.4850 - acc: 0.7854
4864/6557 [=====================>........] - ETA: 0s - loss: 0.4795 - acc: 0.7866
5376/6557 [=======================>......] - ETA: 0s - loss: 0.4933 - acc: 0.7799
5888/6557 [=========================>....] - ETA: 0s - loss: 0.5003 - acc: 0.7765
6400/6557 [============================>.] - ETA: 0s - loss: 0.4967 - acc: 0.7780
6557/6557 [==============================] - 1s 108us/step - loss: 0.4974 - acc: 0.7781 - val_loss: 0.5248 - val_acc: 0.7406
Epoch 7/30

 256/6557 [>.............................] - ETA: 0s - loss: 0.3753 - acc: 0.8320
 768/6557 [==>...........................] - ETA: 0s - loss: 0.3904 - acc: 0.8268
1280/6557 [====>.........................] - ETA: 0s - loss: 0.4171 - acc: 0.8148
1792/6557 [=======>......................] - ETA: 0s - loss: 0.4213 - acc: 0.8131
2304/6557 [=========>....................] - ETA: 0s - loss: 0.4158 - acc: 0.8177
2816/6557 [===========>..................] - ETA: 0s - loss: 0.4294 - acc: 0.8104
3328/6557 [==============>...............] - ETA: 0s - loss: 0.4329 - acc: 0.8062
3840/6557 [================>.............] - ETA: 0s - loss: 0.4395 - acc: 0.8070
4352/6557 [==================>...........] - ETA: 0s - loss: 0.4508 - acc: 0.8015
4864/6557 [=====================>........] - ETA: 0s - loss: 0.4516 - acc: 0.8004
5376/6557 [=======================>......] - ETA: 0s - loss: 0.4496 - acc: 0.8021
5888/6557 [=========================>....] - ETA: 0s - loss: 0.4472 - acc: 0.8050
6400/6557 [============================>.] - ETA: 0s - loss: 0.4429 - acc: 0.8066
6557/6557 [==============================] - 1s 108us/step - loss: 0.4410 - acc: 0.8065 - val_loss: 0.5337 - val_acc: 0.7503
Epoch 8/30

 256/6557 [>.............................] - ETA: 0s - loss: 0.4225 - acc: 0.8320
 768/6557 [==>...........................] - ETA: 0s - loss: 0.3664 - acc: 0.8529
1280/6557 [====>.........................] - ETA: 0s - loss: 0.3794 - acc: 0.8430
1792/6557 [=======>......................] - ETA: 0s - loss: 0.3858 - acc: 0.8376
2304/6557 [=========>....................] - ETA: 0s - loss: 0.3818 - acc: 0.8411
2816/6557 [===========>..................] - ETA: 0s - loss: 0.3809 - acc: 0.8381
3328/6557 [==============>...............] - ETA: 0s - loss: 0.3813 - acc: 0.8395
3840/6557 [================>.............] - ETA: 0s - loss: 0.3875 - acc: 0.8359
4352/6557 [==================>...........] - ETA: 0s - loss: 0.3987 - acc: 0.8320
4864/6557 [=====================>........] - ETA: 0s - loss: 0.4034 - acc: 0.8298
5376/6557 [=======================>......] - ETA: 0s - loss: 0.4041 - acc: 0.8292
5888/6557 [=========================>....] - ETA: 0s - loss: 0.4045 - acc: 0.8288
6400/6557 [============================>.] - ETA: 0s - loss: 0.4112 - acc: 0.8244
6557/6557 [==============================] - 1s 107us/step - loss: 0.4135 - acc: 0.8235 - val_loss: 0.6161 - val_acc: 0.7006
Epoch 9/30

 256/6557 [>.............................] - ETA: 0s - loss: 0.4176 - acc: 0.8242
 768/6557 [==>...........................] - ETA: 0s - loss: 0.4109 - acc: 0.8164
1280/6557 [====>.........................] - ETA: 0s - loss: 0.3852 - acc: 0.8383
1792/6557 [=======>......................] - ETA: 0s - loss: 0.3579 - acc: 0.8482
2304/6557 [=========>....................] - ETA: 0s - loss: 0.3483 - acc: 0.8494
2816/6557 [===========>..................] - ETA: 0s - loss: 0.3365 - acc: 0.8548
3328/6557 [==============>...............] - ETA: 0s - loss: 0.3336 - acc: 0.8570
3840/6557 [================>.............] - ETA: 0s - loss: 0.3355 - acc: 0.8557
4352/6557 [==================>...........] - ETA: 0s - loss: 0.3334 - acc: 0.8575
4864/6557 [=====================>........] - ETA: 0s - loss: 0.3327 - acc: 0.8588
5376/6557 [=======================>......] - ETA: 0s - loss: 0.3339 - acc: 0.8596
5888/6557 [=========================>....] - ETA: 0s - loss: 0.3319 - acc: 0.8611
6400/6557 [============================>.] - ETA: 0s - loss: 0.3314 - acc: 0.8622
6557/6557 [==============================] - 1s 106us/step - loss: 0.3306 - acc: 0.8623 - val_loss: 0.5209 - val_acc: 0.7503
Epoch 10/30

 256/6557 [>.............................] - ETA: 0s - loss: 0.3426 - acc: 0.8633
 768/6557 [==>...........................] - ETA: 0s - loss: 0.3045 - acc: 0.8750
1280/6557 [====>.........................] - ETA: 0s - loss: 0.3047 - acc: 0.8734
1792/6557 [=======>......................] - ETA: 0s - loss: 0.3080 - acc: 0.8717
2304/6557 [=========>....................] - ETA: 0s - loss: 0.3055 - acc: 0.8728
2816/6557 [===========>..................] - ETA: 0s - loss: 0.3170 - acc: 0.8675
3328/6557 [==============>...............] - ETA: 0s - loss: 0.3143 - acc: 0.8699
3840/6557 [================>.............] - ETA: 0s - loss: 0.3090 - acc: 0.8740
4352/6557 [==================>...........] - ETA: 0s - loss: 0.3086 - acc: 0.8722
4864/6557 [=====================>........] - ETA: 0s - loss: 0.3086 - acc: 0.8729
5376/6557 [=======================>......] - ETA: 0s - loss: 0.3104 - acc: 0.8720
5888/6557 [=========================>....] - ETA: 0s - loss: 0.3135 - acc: 0.8708
6400/6557 [============================>.] - ETA: 0s - loss: 0.3124 - acc: 0.8719
6557/6557 [==============================] - 1s 110us/step - loss: 0.3119 - acc: 0.8724 - val_loss: 0.5147 - val_acc: 0.7539
Epoch 11/30

 256/6557 [>.............................] - ETA: 0s - loss: 0.3268 - acc: 0.8633
 768/6557 [==>...........................] - ETA: 0s - loss: 0.2985 - acc: 0.8776
1280/6557 [====>.........................] - ETA: 0s - loss: 0.3158 - acc: 0.8672
1792/6557 [=======>......................] - ETA: 0s - loss: 0.3080 - acc: 0.8744
2304/6557 [=========>....................] - ETA: 0s - loss: 0.3054 - acc: 0.8767
2816/6557 [===========>..................] - ETA: 0s - loss: 0.3079 - acc: 0.8757
3328/6557 [==============>...............] - ETA: 0s - loss: 0.3071 - acc: 0.8747
3840/6557 [================>.............] - ETA: 0s - loss: 0.3052 - acc: 0.8766
4352/6557 [==================>...........] - ETA: 0s - loss: 0.3032 - acc: 0.8775
4864/6557 [=====================>........] - ETA: 0s - loss: 0.3051 - acc: 0.8771
5376/6557 [=======================>......] - ETA: 0s - loss: 0.3064 - acc: 0.8770
5888/6557 [=========================>....] - ETA: 0s - loss: 0.3069 - acc: 0.8764
6400/6557 [============================>.] - ETA: 0s - loss: 0.3082 - acc: 0.8753
6557/6557 [==============================] - 1s 107us/step - loss: 0.3073 - acc: 0.8748 - val_loss: 0.5140 - val_acc: 0.7527
Epoch 12/30

 256/6557 [>.............................] - ETA: 0s - loss: 0.2943 - acc: 0.8789
 768/6557 [==>...........................] - ETA: 0s - loss: 0.3223 - acc: 0.8594
1280/6557 [====>.........................] - ETA: 0s - loss: 0.3203 - acc: 0.8656
1792/6557 [=======>......................] - ETA: 0s - loss: 0.3003 - acc: 0.8750
2304/6557 [=========>....................] - ETA: 0s - loss: 0.3058 - acc: 0.8737
2816/6557 [===========>..................] - ETA: 0s - loss: 0.3031 - acc: 0.8732
3328/6557 [==============>...............] - ETA: 0s - loss: 0.3017 - acc: 0.8756
3840/6557 [================>.............] - ETA: 0s - loss: 0.3029 - acc: 0.8760
4352/6557 [==================>...........] - ETA: 0s - loss: 0.3072 - acc: 0.8741
4864/6557 [=====================>........] - ETA: 0s - loss: 0.3049 - acc: 0.8756
5376/6557 [=======================>......] - ETA: 0s - loss: 0.3038 - acc: 0.8763
5888/6557 [=========================>....] - ETA: 0s - loss: 0.3036 - acc: 0.8769
6400/6557 [============================>.] - ETA: 0s - loss: 0.3013 - acc: 0.8777
6557/6557 [==============================] - 1s 107us/step - loss: 0.3014 - acc: 0.8772 - val_loss: 0.5195 - val_acc: 0.7491
Epoch 13/30

 256/6557 [>.............................] - ETA: 0s - loss: 0.2995 - acc: 0.8945
 768/6557 [==>...........................] - ETA: 0s - loss: 0.3023 - acc: 0.8815
1280/6557 [====>.........................] - ETA: 0s - loss: 0.2885 - acc: 0.8898
1792/6557 [=======>......................] - ETA: 0s - loss: 0.2951 - acc: 0.8856
2304/6557 [=========>....................] - ETA: 0s - loss: 0.2954 - acc: 0.8806
2816/6557 [===========>..................] - ETA: 0s - loss: 0.2907 - acc: 0.8817
3328/6557 [==============>...............] - ETA: 0s - loss: 0.2927 - acc: 0.8828
3840/6557 [================>.............] - ETA: 0s - loss: 0.2941 - acc: 0.8810
4352/6557 [==================>...........] - ETA: 0s - loss: 0.2922 - acc: 0.8824
4864/6557 [=====================>........] - ETA: 0s - loss: 0.2880 - acc: 0.8832
5376/6557 [=======================>......] - ETA: 0s - loss: 0.2912 - acc: 0.8819
5888/6557 [=========================>....] - ETA: 0s - loss: 0.2899 - acc: 0.8826
6400/6557 [============================>.] - ETA: 0s - loss: 0.2896 - acc: 0.8828
6557/6557 [==============================] - 1s 108us/step - loss: 0.2898 - acc: 0.8833 - val_loss: 0.5115 - val_acc: 0.7552
Epoch 14/30

 256/6557 [>.............................] - ETA: 0s - loss: 0.2770 - acc: 0.8750
 768/6557 [==>...........................] - ETA: 0s - loss: 0.2726 - acc: 0.8880
1280/6557 [====>.........................] - ETA: 0s - loss: 0.2627 - acc: 0.8938
1792/6557 [=======>......................] - ETA: 0s - loss: 0.2591 - acc: 0.8940
2304/6557 [=========>....................] - ETA: 0s - loss: 0.2683 - acc: 0.8889
2816/6557 [===========>..................] - ETA: 0s - loss: 0.2690 - acc: 0.8892
3328/6557 [==============>...............] - ETA: 0s - loss: 0.2715 - acc: 0.8909
3840/6557 [================>.............] - ETA: 0s - loss: 0.2727 - acc: 0.8909
4352/6557 [==================>...........] - ETA: 0s - loss: 0.2762 - acc: 0.8897
4864/6557 [=====================>........] - ETA: 0s - loss: 0.2778 - acc: 0.8884
5376/6557 [=======================>......] - ETA: 0s - loss: 0.2795 - acc: 0.8867
5888/6557 [=========================>....] - ETA: 0s - loss: 0.2812 - acc: 0.8859
6400/6557 [============================>.] - ETA: 0s - loss: 0.2818 - acc: 0.8859
6557/6557 [==============================] - 1s 107us/step - loss: 0.2835 - acc: 0.8853 - val_loss: 0.5117 - val_acc: 0.7503
Epoch 15/30

 256/6557 [>.............................] - ETA: 0s - loss: 0.2908 - acc: 0.8984
 768/6557 [==>...........................] - ETA: 0s - loss: 0.2794 - acc: 0.8945
1536/6557 [======>.......................] - ETA: 0s - loss: 0.2827 - acc: 0.8939
2048/6557 [========>.....................] - ETA: 0s - loss: 0.2768 - acc: 0.8940
2560/6557 [==========>...................] - ETA: 0s - loss: 0.2840 - acc: 0.8922
3072/6557 [=============>................] - ETA: 0s - loss: 0.2895 - acc: 0.8867
3584/6557 [===============>..............] - ETA: 0s - loss: 0.2958 - acc: 0.8823
4352/6557 [==================>...........] - ETA: 0s - loss: 0.2895 - acc: 0.8851
4864/6557 [=====================>........] - ETA: 0s - loss: 0.2865 - acc: 0.8857
5376/6557 [=======================>......] - ETA: 0s - loss: 0.2844 - acc: 0.8867
5888/6557 [=========================>....] - ETA: 0s - loss: 0.2850 - acc: 0.8869
6400/6557 [============================>.] - ETA: 0s - loss: 0.2846 - acc: 0.8878
6557/6557 [==============================] - 1s 107us/step - loss: 0.2852 - acc: 0.8874 - val_loss: 0.5076 - val_acc: 0.7539
Epoch 16/30

 256/6557 [>.............................] - ETA: 0s - loss: 0.2899 - acc: 0.8867
 768/6557 [==>...........................] - ETA: 0s - loss: 0.2738 - acc: 0.8932
1280/6557 [====>.........................] - ETA: 0s - loss: 0.2744 - acc: 0.8883
1792/6557 [=======>......................] - ETA: 0s - loss: 0.2798 - acc: 0.8811
2304/6557 [=========>....................] - ETA: 0s - loss: 0.2706 - acc: 0.8867
2816/6557 [===========>..................] - ETA: 0s - loss: 0.2751 - acc: 0.8849
3328/6557 [==============>...............] - ETA: 0s - loss: 0.2766 - acc: 0.8849
3840/6557 [================>.............] - ETA: 0s - loss: 0.2747 - acc: 0.8865
4352/6557 [==================>...........] - ETA: 0s - loss: 0.2738 - acc: 0.8888
4864/6557 [=====================>........] - ETA: 0s - loss: 0.2719 - acc: 0.8900
5376/6557 [=======================>......] - ETA: 0s - loss: 0.2734 - acc: 0.8878
5888/6557 [=========================>....] - ETA: 0s - loss: 0.2757 - acc: 0.8867
6400/6557 [============================>.] - ETA: 0s - loss: 0.2773 - acc: 0.8862
6557/6557 [==============================] - 1s 108us/step - loss: 0.2789 - acc: 0.8858 - val_loss: 0.5077 - val_acc: 0.7576
Epoch 17/30

 256/6557 [>.............................] - ETA: 0s - loss: 0.2577 - acc: 0.9102
 768/6557 [==>...........................] - ETA: 0s - loss: 0.2916 - acc: 0.8828
1280/6557 [====>.........................] - ETA: 0s - loss: 0.2661 - acc: 0.8945
1792/6557 [=======>......................] - ETA: 0s - loss: 0.2665 - acc: 0.8968
2304/6557 [=========>....................] - ETA: 0s - loss: 0.2630 - acc: 0.9002
2816/6557 [===========>..................] - ETA: 0s - loss: 0.2588 - acc: 0.9006
3328/6557 [==============>...............] - ETA: 0s - loss: 0.2595 - acc: 0.9020
3840/6557 [================>.............] - ETA: 0s - loss: 0.2634 - acc: 0.8992
4352/6557 [==================>...........] - ETA: 0s - loss: 0.2654 - acc: 0.8987
4864/6557 [=====================>........] - ETA: 0s - loss: 0.2628 - acc: 0.8999
5632/6557 [========================>.....] - ETA: 0s - loss: 0.2656 - acc: 0.8988
6144/6557 [===========================>..] - ETA: 0s - loss: 0.2665 - acc: 0.8983
6557/6557 [==============================] - 1s 106us/step - loss: 0.2671 - acc: 0.8984 - val_loss: 0.5046 - val_acc: 0.7636
Epoch 18/30

 256/6557 [>.............................] - ETA: 0s - loss: 0.2354 - acc: 0.9102
 768/6557 [==>...........................] - ETA: 0s - loss: 0.2376 - acc: 0.9128
1280/6557 [====>.........................] - ETA: 0s - loss: 0.2448 - acc: 0.9102
1792/6557 [=======>......................] - ETA: 0s - loss: 0.2543 - acc: 0.9062
2304/6557 [=========>....................] - ETA: 0s - loss: 0.2535 - acc: 0.9071
2816/6557 [===========>..................] - ETA: 0s - loss: 0.2538 - acc: 0.9059
3328/6557 [==============>...............] - ETA: 0s - loss: 0.2562 - acc: 0.9023
3840/6557 [================>.............] - ETA: 0s - loss: 0.2572 - acc: 0.9013
4352/6557 [==================>...........] - ETA: 0s - loss: 0.2570 - acc: 0.9012
4864/6557 [=====================>........] - ETA: 0s - loss: 0.2563 - acc: 0.9021
5376/6557 [=======================>......] - ETA: 0s - loss: 0.2581 - acc: 0.8988
5888/6557 [=========================>....] - ETA: 0s - loss: 0.2561 - acc: 0.9001
6400/6557 [============================>.] - ETA: 0s - loss: 0.2600 - acc: 0.8986
6557/6557 [==============================] - 1s 108us/step - loss: 0.2591 - acc: 0.8990 - val_loss: 0.5042 - val_acc: 0.7661
Epoch 19/30

 256/6557 [>.............................] - ETA: 0s - loss: 0.2391 - acc: 0.9141
 768/6557 [==>...........................] - ETA: 0s - loss: 0.2420 - acc: 0.9115
1280/6557 [====>.........................] - ETA: 0s - loss: 0.2440 - acc: 0.9133
1792/6557 [=======>......................] - ETA: 0s - loss: 0.2420 - acc: 0.9118
2304/6557 [=========>....................] - ETA: 0s - loss: 0.2381 - acc: 0.9132
2816/6557 [===========>..................] - ETA: 0s - loss: 0.2397 - acc: 0.9126
3328/6557 [==============>...............] - ETA: 0s - loss: 0.2394 - acc: 0.9108
3840/6557 [================>.............] - ETA: 0s - loss: 0.2489 - acc: 0.9052
4352/6557 [==================>...........] - ETA: 0s - loss: 0.2485 - acc: 0.9056
4864/6557 [=====================>........] - ETA: 0s - loss: 0.2514 - acc: 0.9030
5376/6557 [=======================>......] - ETA: 0s - loss: 0.2533 - acc: 0.9014
5888/6557 [=========================>....] - ETA: 0s - loss: 0.2561 - acc: 0.8995
6400/6557 [============================>.] - ETA: 0s - loss: 0.2542 - acc: 0.9005
6557/6557 [==============================] - 1s 108us/step - loss: 0.2552 - acc: 0.9004 - val_loss: 0.5096 - val_acc: 0.7576
Epoch 20/30

 256/6557 [>.............................] - ETA: 0s - loss: 0.2707 - acc: 0.8867
 768/6557 [==>...........................] - ETA: 0s - loss: 0.2575 - acc: 0.8984
1280/6557 [====>.........................] - ETA: 0s - loss: 0.2603 - acc: 0.8984
1792/6557 [=======>......................] - ETA: 0s - loss: 0.2587 - acc: 0.8984
2304/6557 [=========>....................] - ETA: 0s - loss: 0.2553 - acc: 0.8993
2816/6557 [===========>..................] - ETA: 0s - loss: 0.2612 - acc: 0.8970
3328/6557 [==============>...............] - ETA: 0s - loss: 0.2558 - acc: 0.9008
3840/6557 [================>.............] - ETA: 0s - loss: 0.2591 - acc: 0.8977
4352/6557 [==================>...........] - ETA: 0s - loss: 0.2548 - acc: 0.9017
4864/6557 [=====================>........] - ETA: 0s - loss: 0.2585 - acc: 0.8995
5376/6557 [=======================>......] - ETA: 0s - loss: 0.2593 - acc: 0.8986
5888/6557 [=========================>....] - ETA: 0s - loss: 0.2621 - acc: 0.8972
6400/6557 [============================>.] - ETA: 0s - loss: 0.2641 - acc: 0.8967
6557/6557 [==============================] - 1s 110us/step - loss: 0.2646 - acc: 0.8963 - val_loss: 0.5071 - val_acc: 0.7624
Epoch 21/30

 256/6557 [>.............................] - ETA: 0s - loss: 0.2250 - acc: 0.9023
 768/6557 [==>...........................] - ETA: 0s - loss: 0.2266 - acc: 0.9154
1280/6557 [====>.........................] - ETA: 0s - loss: 0.2407 - acc: 0.9102
1792/6557 [=======>......................] - ETA: 0s - loss: 0.2406 - acc: 0.9068
2304/6557 [=========>....................] - ETA: 0s - loss: 0.2398 - acc: 0.9071
2816/6557 [===========>..................] - ETA: 0s - loss: 0.2405 - acc: 0.9077
3328/6557 [==============>...............] - ETA: 0s - loss: 0.2365 - acc: 0.9099
3840/6557 [================>.............] - ETA: 0s - loss: 0.2362 - acc: 0.9112
4352/6557 [==================>...........] - ETA: 0s - loss: 0.2391 - acc: 0.9108
4864/6557 [=====================>........] - ETA: 0s - loss: 0.2415 - acc: 0.9104
5376/6557 [=======================>......] - ETA: 0s - loss: 0.2403 - acc: 0.9111
5888/6557 [=========================>....] - ETA: 0s - loss: 0.2444 - acc: 0.9098
6400/6557 [============================>.] - ETA: 0s - loss: 0.2455 - acc: 0.9103
6557/6557 [==============================] - 1s 108us/step - loss: 0.2463 - acc: 0.9100 - val_loss: 0.5076 - val_acc: 0.7624
Epoch 22/30

 256/6557 [>.............................] - ETA: 0s - loss: 0.2327 - acc: 0.9180
 768/6557 [==>...........................] - ETA: 0s - loss: 0.2444 - acc: 0.9193
1280/6557 [====>.........................] - ETA: 0s - loss: 0.2377 - acc: 0.9156
1792/6557 [=======>......................] - ETA: 0s - loss: 0.2314 - acc: 0.9169
2304/6557 [=========>....................] - ETA: 0s - loss: 0.2432 - acc: 0.9084
2816/6557 [===========>..................] - ETA: 0s - loss: 0.2446 - acc: 0.9073
3328/6557 [==============>...............] - ETA: 0s - loss: 0.2514 - acc: 0.9044
3840/6557 [================>.............] - ETA: 0s - loss: 0.2536 - acc: 0.9044
4352/6557 [==================>...........] - ETA: 0s - loss: 0.2532 - acc: 0.9042
4864/6557 [=====================>........] - ETA: 0s - loss: 0.2474 - acc: 0.9077
5376/6557 [=======================>......] - ETA: 0s - loss: 0.2497 - acc: 0.9066
5888/6557 [=========================>....] - ETA: 0s - loss: 0.2465 - acc: 0.9083
6400/6557 [============================>.] - ETA: 0s - loss: 0.2460 - acc: 0.9087
6557/6557 [==============================] - 1s 106us/step - loss: 0.2458 - acc: 0.9091 - val_loss: 0.5083 - val_acc: 0.7612
Epoch 23/30

 256/6557 [>.............................] - ETA: 0s - loss: 0.2590 - acc: 0.9023
1024/6557 [===>..........................] - ETA: 0s - loss: 0.2683 - acc: 0.8994
1536/6557 [======>.......................] - ETA: 0s - loss: 0.2584 - acc: 0.8991
2048/6557 [========>.....................] - ETA: 0s - loss: 0.2596 - acc: 0.8970
2560/6557 [==========>...................] - ETA: 0s - loss: 0.2575 - acc: 0.8992
3072/6557 [=============>................] - ETA: 0s - loss: 0.2535 - acc: 0.9010
3584/6557 [===============>..............] - ETA: 0s - loss: 0.2485 - acc: 0.9032
4096/6557 [=================>............] - ETA: 0s - loss: 0.2523 - acc: 0.9019
4608/6557 [====================>.........] - ETA: 0s - loss: 0.2498 - acc: 0.9036
5120/6557 [======================>.......] - ETA: 0s - loss: 0.2473 - acc: 0.9047
5632/6557 [========================>.....] - ETA: 0s - loss: 0.2470 - acc: 0.9052
6144/6557 [===========================>..] - ETA: 0s - loss: 0.2497 - acc: 0.9043
6557/6557 [==============================] - 1s 105us/step - loss: 0.2487 - acc: 0.9048 - val_loss: 0.5082 - val_acc: 0.7612
2018-10-25 17:57:14,141 : INFO : loading best model weights
2018-10-25 17:57:14,655 : INFO : computing and saving metrics
             precision    recall  f1-score   support

   negative       0.78      0.73      0.76       408
   positive       0.75      0.80      0.78       417

avg / total       0.77      0.77      0.77       825

