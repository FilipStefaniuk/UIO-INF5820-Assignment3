Using TensorFlow backend.
2018-10-25 17:25:58,347 : INFO : training model in static mode
2018-10-25 17:25:58,348 : INFO : loading and preprocessing dataset
2018-10-25 17:25:59,119 : INFO : training: 6557 samples, validation: 825 samples
2018-10-25 17:25:59,119 : INFO : using 13295 raw words
2018-10-25 17:25:59,119 : INFO : building embedding layer
2018-10-25 17:25:59,203 : INFO : loading 2519370 words for fastText model from /usit/abel/u1/filipste/vectors/wiki.en.fasttext.bin
2018-10-25 17:28:16,291 : INFO : loading weights for 2519370 words for fastText model from /usit/abel/u1/filipste/vectors/wiki.en.fasttext.bin
2018-10-25 17:39:03,223 : INFO : loaded (2519370, 300) weight matrix for fastText model from /usit/abel/u1/filipste/vectors/wiki.en.fasttext.bin
2018-10-25 17:39:03,617 : WARNING : there are 1 oov tokens
2018-10-25 17:39:07,267 : INFO : building model
2018-10-25 17:39:08.992165: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties: 
name: Tesla K20Xm major: 3 minor: 5 memoryClockRate(GHz): 0.732
pciBusID: 0000:84:00.0
totalMemory: 5.57GiB freeMemory: 5.49GiB
2018-10-25 17:39:08.992249: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0
2018-10-25 17:39:09.317836: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-10-25 17:39:09.317951: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 
2018-10-25 17:39:09.317967: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N 
2018-10-25 17:39:09.318247: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5278 MB memory) -> physical GPU (device: 0, name: Tesla K20Xm, pci bus id: 0000:84:00.0, compute capability: 3.5)
2018-10-25 17:39:09,686 : INFO : training the model
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 50)           0                                            
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 50, 300)      3988800     input_1[0][0]                    
__________________________________________________________________________________________________
conv1d_1 (Conv1D)               (None, 48, 100)      90100       embedding_1[0][0]                
__________________________________________________________________________________________________
conv1d_2 (Conv1D)               (None, 47, 100)      120100      embedding_1[0][0]                
__________________________________________________________________________________________________
conv1d_3 (Conv1D)               (None, 46, 100)      150100      embedding_1[0][0]                
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 48, 100)      0           conv1d_1[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 47, 100)      0           conv1d_2[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 100)      0           conv1d_3[0][0]                   
__________________________________________________________________________________________________
global_max_pooling1d_1 (GlobalM (None, 100)          0           activation_1[0][0]               
__________________________________________________________________________________________________
global_max_pooling1d_2 (GlobalM (None, 100)          0           activation_2[0][0]               
__________________________________________________________________________________________________
global_max_pooling1d_3 (GlobalM (None, 100)          0           activation_3[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 300)          0           global_max_pooling1d_1[0][0]     
                                                                 global_max_pooling1d_2[0][0]     
                                                                 global_max_pooling1d_3[0][0]     
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 300)          0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 2)            602         dropout_1[0][0]                  
==================================================================================================
Total params: 4,349,702
Trainable params: 360,902
Non-trainable params: 3,988,800
__________________________________________________________________________________________________
Train on 6557 samples, validate on 825 samples
Epoch 1/30

 256/6557 [>.............................] - ETA: 58s - loss: 0.8910 - acc: 0.4766
 768/6557 [==>...........................] - ETA: 18s - loss: 0.8649 - acc: 0.5104
1280/6557 [====>.........................] - ETA: 10s - loss: 0.8511 - acc: 0.5219
1792/6557 [=======>......................] - ETA: 6s - loss: 0.8338 - acc: 0.5184 
2304/6557 [=========>....................] - ETA: 4s - loss: 0.8384 - acc: 0.5208
2816/6557 [===========>..................] - ETA: 3s - loss: 0.8258 - acc: 0.5245
3328/6557 [==============>...............] - ETA: 2s - loss: 0.8218 - acc: 0.5279
3840/6557 [================>.............] - ETA: 1s - loss: 0.8042 - acc: 0.5378
4352/6557 [==================>...........] - ETA: 1s - loss: 0.7891 - acc: 0.5457
4864/6557 [=====================>........] - ETA: 0s - loss: 0.7765 - acc: 0.5524
5376/6557 [=======================>......] - ETA: 0s - loss: 0.7636 - acc: 0.5606
5888/6557 [=========================>....] - ETA: 0s - loss: 0.7521 - acc: 0.5673
6400/6557 [============================>.] - ETA: 0s - loss: 0.7443 - acc: 0.5733
6557/6557 [==============================] - 4s 591us/step - loss: 0.7415 - acc: 0.5754 - val_loss: 0.5604 - val_acc: 0.7152
Epoch 2/30

 256/6557 [>.............................] - ETA: 0s - loss: 0.5801 - acc: 0.6641
1024/6557 [===>..........................] - ETA: 0s - loss: 0.5887 - acc: 0.6748
1536/6557 [======>.......................] - ETA: 0s - loss: 0.5831 - acc: 0.6810
2048/6557 [========>.....................] - ETA: 0s - loss: 0.5818 - acc: 0.6885
2560/6557 [==========>...................] - ETA: 0s - loss: 0.5847 - acc: 0.6867
3072/6557 [=============>................] - ETA: 0s - loss: 0.5913 - acc: 0.6846
3584/6557 [===============>..............] - ETA: 0s - loss: 0.5840 - acc: 0.6920
4096/6557 [=================>............] - ETA: 0s - loss: 0.5788 - acc: 0.6965
4608/6557 [====================>.........] - ETA: 0s - loss: 0.5715 - acc: 0.7027
5120/6557 [======================>.......] - ETA: 0s - loss: 0.5667 - acc: 0.7055
5632/6557 [========================>.....] - ETA: 0s - loss: 0.5639 - acc: 0.7081
6144/6557 [===========================>..] - ETA: 0s - loss: 0.5598 - acc: 0.7131
6557/6557 [==============================] - 1s 104us/step - loss: 0.5590 - acc: 0.7147 - val_loss: 0.5399 - val_acc: 0.7152
Epoch 3/30

 256/6557 [>.............................] - ETA: 0s - loss: 0.5192 - acc: 0.7188
 768/6557 [==>...........................] - ETA: 0s - loss: 0.5119 - acc: 0.7357
1280/6557 [====>.........................] - ETA: 0s - loss: 0.5074 - acc: 0.7531
1792/6557 [=======>......................] - ETA: 0s - loss: 0.5111 - acc: 0.7439
2304/6557 [=========>....................] - ETA: 0s - loss: 0.5108 - acc: 0.7409
2816/6557 [===========>..................] - ETA: 0s - loss: 0.5046 - acc: 0.7525
3584/6557 [===============>..............] - ETA: 0s - loss: 0.5079 - acc: 0.7511
4352/6557 [==================>...........] - ETA: 0s - loss: 0.5002 - acc: 0.7601
4864/6557 [=====================>........] - ETA: 0s - loss: 0.4995 - acc: 0.7609
5376/6557 [=======================>......] - ETA: 0s - loss: 0.4989 - acc: 0.7615
5888/6557 [=========================>....] - ETA: 0s - loss: 0.4956 - acc: 0.7641
6557/6557 [==============================] - 1s 104us/step - loss: 0.4910 - acc: 0.7674 - val_loss: 0.5567 - val_acc: 0.6861
Epoch 4/30

 256/6557 [>.............................] - ETA: 0s - loss: 0.5155 - acc: 0.7500
 768/6557 [==>...........................] - ETA: 0s - loss: 0.4601 - acc: 0.7891
1536/6557 [======>.......................] - ETA: 0s - loss: 0.4449 - acc: 0.8034
2048/6557 [========>.....................] - ETA: 0s - loss: 0.4482 - acc: 0.7979
2560/6557 [==========>...................] - ETA: 0s - loss: 0.4556 - acc: 0.7895
3072/6557 [=============>................] - ETA: 0s - loss: 0.4534 - acc: 0.7920
3584/6557 [===============>..............] - ETA: 0s - loss: 0.4497 - acc: 0.7924
4096/6557 [=================>............] - ETA: 0s - loss: 0.4478 - acc: 0.7959
4864/6557 [=====================>........] - ETA: 0s - loss: 0.4462 - acc: 0.7961
5376/6557 [=======================>......] - ETA: 0s - loss: 0.4551 - acc: 0.7889
6144/6557 [===========================>..] - ETA: 0s - loss: 0.4680 - acc: 0.7803
6557/6557 [==============================] - 1s 103us/step - loss: 0.4680 - acc: 0.7808 - val_loss: 0.4655 - val_acc: 0.7794
Epoch 5/30

 256/6557 [>.............................] - ETA: 0s - loss: 0.4244 - acc: 0.8008
 768/6557 [==>...........................] - ETA: 0s - loss: 0.4372 - acc: 0.7969
1536/6557 [======>.......................] - ETA: 0s - loss: 0.4562 - acc: 0.7780
2304/6557 [=========>....................] - ETA: 0s - loss: 0.4599 - acc: 0.7752
2816/6557 [===========>..................] - ETA: 0s - loss: 0.4504 - acc: 0.7844
3328/6557 [==============>...............] - ETA: 0s - loss: 0.4439 - acc: 0.7915
3840/6557 [================>.............] - ETA: 0s - loss: 0.4458 - acc: 0.7898
4352/6557 [==================>...........] - ETA: 0s - loss: 0.4442 - acc: 0.7920
4864/6557 [=====================>........] - ETA: 0s - loss: 0.4402 - acc: 0.7963
5376/6557 [=======================>......] - ETA: 0s - loss: 0.4371 - acc: 0.7995
5888/6557 [=========================>....] - ETA: 0s - loss: 0.4321 - acc: 0.8033
6400/6557 [============================>.] - ETA: 0s - loss: 0.4300 - acc: 0.8045
6557/6557 [==============================] - 1s 105us/step - loss: 0.4299 - acc: 0.8046 - val_loss: 0.4467 - val_acc: 0.7915
Epoch 6/30

 256/6557 [>.............................] - ETA: 0s - loss: 0.3390 - acc: 0.8828
 768/6557 [==>...........................] - ETA: 0s - loss: 0.3755 - acc: 0.8620
1280/6557 [====>.........................] - ETA: 0s - loss: 0.3794 - acc: 0.8477
1792/6557 [=======>......................] - ETA: 0s - loss: 0.3823 - acc: 0.8438
2304/6557 [=========>....................] - ETA: 0s - loss: 0.3817 - acc: 0.8424
2816/6557 [===========>..................] - ETA: 0s - loss: 0.3817 - acc: 0.8384
3328/6557 [==============>...............] - ETA: 0s - loss: 0.3883 - acc: 0.8332
3840/6557 [================>.............] - ETA: 0s - loss: 0.3851 - acc: 0.8349
4352/6557 [==================>...........] - ETA: 0s - loss: 0.3879 - acc: 0.8323
4864/6557 [=====================>........] - ETA: 0s - loss: 0.3897 - acc: 0.8308
5376/6557 [=======================>......] - ETA: 0s - loss: 0.3925 - acc: 0.8268
5888/6557 [=========================>....] - ETA: 0s - loss: 0.3976 - acc: 0.8225
6400/6557 [============================>.] - ETA: 0s - loss: 0.3976 - acc: 0.8217
6557/6557 [==============================] - 1s 106us/step - loss: 0.3969 - acc: 0.8225 - val_loss: 0.4463 - val_acc: 0.7964
Epoch 7/30

 256/6557 [>.............................] - ETA: 0s - loss: 0.3340 - acc: 0.8711
 768/6557 [==>...........................] - ETA: 0s - loss: 0.3361 - acc: 0.8698
1280/6557 [====>.........................] - ETA: 0s - loss: 0.3430 - acc: 0.8672
1792/6557 [=======>......................] - ETA: 0s - loss: 0.3528 - acc: 0.8588
2560/6557 [==========>...................] - ETA: 0s - loss: 0.3585 - acc: 0.8520
3072/6557 [=============>................] - ETA: 0s - loss: 0.3583 - acc: 0.8529
3840/6557 [================>.............] - ETA: 0s - loss: 0.3663 - acc: 0.8453
4352/6557 [==================>...........] - ETA: 0s - loss: 0.3710 - acc: 0.8392
5120/6557 [======================>.......] - ETA: 0s - loss: 0.3776 - acc: 0.8328
5888/6557 [=========================>....] - ETA: 0s - loss: 0.3781 - acc: 0.8317
6400/6557 [============================>.] - ETA: 0s - loss: 0.3775 - acc: 0.8336
6557/6557 [==============================] - 1s 105us/step - loss: 0.3761 - acc: 0.8345 - val_loss: 0.4283 - val_acc: 0.8121
Epoch 8/30

 256/6557 [>.............................] - ETA: 0s - loss: 0.3471 - acc: 0.8828
 768/6557 [==>...........................] - ETA: 0s - loss: 0.3646 - acc: 0.8607
1280/6557 [====>.........................] - ETA: 0s - loss: 0.3687 - acc: 0.8523
1792/6557 [=======>......................] - ETA: 0s - loss: 0.3588 - acc: 0.8504
2304/6557 [=========>....................] - ETA: 0s - loss: 0.3513 - acc: 0.8529
2816/6557 [===========>..................] - ETA: 0s - loss: 0.3599 - acc: 0.8484
3328/6557 [==============>...............] - ETA: 0s - loss: 0.3803 - acc: 0.8308
3840/6557 [================>.............] - ETA: 0s - loss: 0.3997 - acc: 0.8164
4352/6557 [==================>...........] - ETA: 0s - loss: 0.4023 - acc: 0.8141
4864/6557 [=====================>........] - ETA: 0s - loss: 0.3992 - acc: 0.8168
5376/6557 [=======================>......] - ETA: 0s - loss: 0.4000 - acc: 0.8160
5888/6557 [=========================>....] - ETA: 0s - loss: 0.4020 - acc: 0.8152
6400/6557 [============================>.] - ETA: 0s - loss: 0.4034 - acc: 0.8152
6557/6557 [==============================] - 1s 109us/step - loss: 0.4019 - acc: 0.8158 - val_loss: 0.4298 - val_acc: 0.8073
Epoch 9/30

 256/6557 [>.............................] - ETA: 0s - loss: 0.3134 - acc: 0.8789
 768/6557 [==>...........................] - ETA: 0s - loss: 0.3153 - acc: 0.8737
1280/6557 [====>.........................] - ETA: 0s - loss: 0.3038 - acc: 0.8867
1792/6557 [=======>......................] - ETA: 0s - loss: 0.3101 - acc: 0.8823
2304/6557 [=========>....................] - ETA: 0s - loss: 0.3112 - acc: 0.8845
2816/6557 [===========>..................] - ETA: 0s - loss: 0.3089 - acc: 0.8842
3328/6557 [==============>...............] - ETA: 0s - loss: 0.3106 - acc: 0.8831
3840/6557 [================>.............] - ETA: 0s - loss: 0.3118 - acc: 0.8828
4352/6557 [==================>...........] - ETA: 0s - loss: 0.3232 - acc: 0.8736
4864/6557 [=====================>........] - ETA: 0s - loss: 0.3278 - acc: 0.8682
5376/6557 [=======================>......] - ETA: 0s - loss: 0.3290 - acc: 0.8668
5888/6557 [=========================>....] - ETA: 0s - loss: 0.3261 - acc: 0.8680
6400/6557 [============================>.] - ETA: 0s - loss: 0.3221 - acc: 0.8709
6557/6557 [==============================] - 1s 107us/step - loss: 0.3206 - acc: 0.8725 - val_loss: 0.4343 - val_acc: 0.8085
Epoch 10/30

 256/6557 [>.............................] - ETA: 0s - loss: 0.2630 - acc: 0.8906
 768/6557 [==>...........................] - ETA: 0s - loss: 0.2708 - acc: 0.8997
1280/6557 [====>.........................] - ETA: 0s - loss: 0.2752 - acc: 0.9039
1792/6557 [=======>......................] - ETA: 0s - loss: 0.2722 - acc: 0.9062
2304/6557 [=========>....................] - ETA: 0s - loss: 0.2819 - acc: 0.9006
2816/6557 [===========>..................] - ETA: 0s - loss: 0.2800 - acc: 0.8995
3328/6557 [==============>...............] - ETA: 0s - loss: 0.2801 - acc: 0.8981
3840/6557 [================>.............] - ETA: 0s - loss: 0.2804 - acc: 0.8982
4352/6557 [==================>...........] - ETA: 0s - loss: 0.2811 - acc: 0.8989
4864/6557 [=====================>........] - ETA: 0s - loss: 0.2779 - acc: 0.8999
5376/6557 [=======================>......] - ETA: 0s - loss: 0.2783 - acc: 0.9007
5888/6557 [=========================>....] - ETA: 0s - loss: 0.2799 - acc: 0.8993
6400/6557 [============================>.] - ETA: 0s - loss: 0.2799 - acc: 0.8988
6557/6557 [==============================] - 1s 108us/step - loss: 0.2797 - acc: 0.8987 - val_loss: 0.4249 - val_acc: 0.8170
Epoch 11/30

 256/6557 [>.............................] - ETA: 0s - loss: 0.3129 - acc: 0.8516
1024/6557 [===>..........................] - ETA: 0s - loss: 0.3088 - acc: 0.8770
1536/6557 [======>.......................] - ETA: 0s - loss: 0.2939 - acc: 0.8854
2048/6557 [========>.....................] - ETA: 0s - loss: 0.2951 - acc: 0.8872
2560/6557 [==========>...................] - ETA: 0s - loss: 0.2881 - acc: 0.8938
3072/6557 [=============>................] - ETA: 0s - loss: 0.2830 - acc: 0.8978
3584/6557 [===============>..............] - ETA: 0s - loss: 0.2851 - acc: 0.8954
4096/6557 [=================>............] - ETA: 0s - loss: 0.2796 - acc: 0.8989
4608/6557 [====================>.........] - ETA: 0s - loss: 0.2788 - acc: 0.9004
5120/6557 [======================>.......] - ETA: 0s - loss: 0.2793 - acc: 0.9006
5632/6557 [========================>.....] - ETA: 0s - loss: 0.2773 - acc: 0.9018
6144/6557 [===========================>..] - ETA: 0s - loss: 0.2779 - acc: 0.9015
6557/6557 [==============================] - 1s 107us/step - loss: 0.2777 - acc: 0.9016 - val_loss: 0.4237 - val_acc: 0.8182
Epoch 12/30

 256/6557 [>.............................] - ETA: 0s - loss: 0.2672 - acc: 0.9141
 768/6557 [==>...........................] - ETA: 0s - loss: 0.2747 - acc: 0.9141
1280/6557 [====>.........................] - ETA: 0s - loss: 0.2715 - acc: 0.9125
1792/6557 [=======>......................] - ETA: 0s - loss: 0.2755 - acc: 0.9090
2304/6557 [=========>....................] - ETA: 0s - loss: 0.2773 - acc: 0.9045
2816/6557 [===========>..................] - ETA: 0s - loss: 0.2772 - acc: 0.9059
3328/6557 [==============>...............] - ETA: 0s - loss: 0.2772 - acc: 0.9056
3840/6557 [================>.............] - ETA: 0s - loss: 0.2738 - acc: 0.9086
4352/6557 [==================>...........] - ETA: 0s - loss: 0.2720 - acc: 0.9092
4864/6557 [=====================>........] - ETA: 0s - loss: 0.2703 - acc: 0.9106
5376/6557 [=======================>......] - ETA: 0s - loss: 0.2715 - acc: 0.9096
5888/6557 [=========================>....] - ETA: 0s - loss: 0.2732 - acc: 0.9093
6400/6557 [============================>.] - ETA: 0s - loss: 0.2720 - acc: 0.9095
6557/6557 [==============================] - 1s 109us/step - loss: 0.2725 - acc: 0.9091 - val_loss: 0.4256 - val_acc: 0.8097
Epoch 13/30

 256/6557 [>.............................] - ETA: 0s - loss: 0.2959 - acc: 0.9023
 768/6557 [==>...........................] - ETA: 0s - loss: 0.2718 - acc: 0.9049
1280/6557 [====>.........................] - ETA: 0s - loss: 0.2719 - acc: 0.9070
1792/6557 [=======>......................] - ETA: 0s - loss: 0.2760 - acc: 0.9007
2304/6557 [=========>....................] - ETA: 0s - loss: 0.2743 - acc: 0.9036
2816/6557 [===========>..................] - ETA: 0s - loss: 0.2762 - acc: 0.9016
3328/6557 [==============>...............] - ETA: 0s - loss: 0.2734 - acc: 0.9038
3840/6557 [================>.............] - ETA: 0s - loss: 0.2735 - acc: 0.9039
4352/6557 [==================>...........] - ETA: 0s - loss: 0.2704 - acc: 0.9072
4864/6557 [=====================>........] - ETA: 0s - loss: 0.2711 - acc: 0.9071
5376/6557 [=======================>......] - ETA: 0s - loss: 0.2700 - acc: 0.9083
5888/6557 [=========================>....] - ETA: 0s - loss: 0.2710 - acc: 0.9068
6400/6557 [============================>.] - ETA: 0s - loss: 0.2717 - acc: 0.9064
6557/6557 [==============================] - 1s 107us/step - loss: 0.2719 - acc: 0.9061 - val_loss: 0.4292 - val_acc: 0.8061
Epoch 14/30

 256/6557 [>.............................] - ETA: 0s - loss: 0.2607 - acc: 0.9023
 768/6557 [==>...........................] - ETA: 0s - loss: 0.2674 - acc: 0.9102
1280/6557 [====>.........................] - ETA: 0s - loss: 0.2681 - acc: 0.9070
2048/6557 [========>.....................] - ETA: 0s - loss: 0.2678 - acc: 0.9082
2560/6557 [==========>...................] - ETA: 0s - loss: 0.2687 - acc: 0.9051
3072/6557 [=============>................] - ETA: 0s - loss: 0.2690 - acc: 0.9043
3584/6557 [===============>..............] - ETA: 0s - loss: 0.2673 - acc: 0.9054
4096/6557 [=================>............] - ETA: 0s - loss: 0.2677 - acc: 0.9062
4608/6557 [====================>.........] - ETA: 0s - loss: 0.2671 - acc: 0.9069
5120/6557 [======================>.......] - ETA: 0s - loss: 0.2661 - acc: 0.9076
5632/6557 [========================>.....] - ETA: 0s - loss: 0.2647 - acc: 0.9086
6144/6557 [===========================>..] - ETA: 0s - loss: 0.2631 - acc: 0.9097
6557/6557 [==============================] - 1s 107us/step - loss: 0.2635 - acc: 0.9088 - val_loss: 0.4263 - val_acc: 0.8048
Epoch 15/30

 256/6557 [>.............................] - ETA: 0s - loss: 0.2760 - acc: 0.8945
 768/6557 [==>...........................] - ETA: 0s - loss: 0.2723 - acc: 0.9023
1280/6557 [====>.........................] - ETA: 0s - loss: 0.2665 - acc: 0.9086
1792/6557 [=======>......................] - ETA: 0s - loss: 0.2771 - acc: 0.8984
2304/6557 [=========>....................] - ETA: 0s - loss: 0.2776 - acc: 0.8989
2816/6557 [===========>..................] - ETA: 0s - loss: 0.2724 - acc: 0.9020
3328/6557 [==============>...............] - ETA: 0s - loss: 0.2723 - acc: 0.9017
3840/6557 [================>.............] - ETA: 0s - loss: 0.2706 - acc: 0.9042
4352/6557 [==================>...........] - ETA: 0s - loss: 0.2713 - acc: 0.9028
4864/6557 [=====================>........] - ETA: 0s - loss: 0.2703 - acc: 0.9030
5376/6557 [=======================>......] - ETA: 0s - loss: 0.2690 - acc: 0.9048
5888/6557 [=========================>....] - ETA: 0s - loss: 0.2689 - acc: 0.9049
6400/6557 [============================>.] - ETA: 0s - loss: 0.2709 - acc: 0.9031
6557/6557 [==============================] - 1s 107us/step - loss: 0.2705 - acc: 0.9039 - val_loss: 0.4250 - val_acc: 0.8109
Epoch 16/30

 256/6557 [>.............................] - ETA: 0s - loss: 0.2548 - acc: 0.9219
 768/6557 [==>...........................] - ETA: 0s - loss: 0.2600 - acc: 0.9141
1280/6557 [====>.........................] - ETA: 0s - loss: 0.2514 - acc: 0.9250
2048/6557 [========>.....................] - ETA: 0s - loss: 0.2534 - acc: 0.9243
2560/6557 [==========>...................] - ETA: 0s - loss: 0.2594 - acc: 0.9191
3072/6557 [=============>................] - ETA: 0s - loss: 0.2572 - acc: 0.9199
3584/6557 [===============>..............] - ETA: 0s - loss: 0.2616 - acc: 0.9160
4096/6557 [=================>............] - ETA: 0s - loss: 0.2613 - acc: 0.9170
4608/6557 [====================>.........] - ETA: 0s - loss: 0.2613 - acc: 0.9169
5120/6557 [======================>.......] - ETA: 0s - loss: 0.2605 - acc: 0.9162
5632/6557 [========================>.....] - ETA: 0s - loss: 0.2606 - acc: 0.9162
6144/6557 [===========================>..] - ETA: 0s - loss: 0.2610 - acc: 0.9157
6557/6557 [==============================] - 1s 108us/step - loss: 0.2619 - acc: 0.9149 - val_loss: 0.4249 - val_acc: 0.8109
2018-10-25 17:39:25,425 : INFO : loading best model weights
2018-10-25 17:39:25,954 : INFO : computing and saving metrics
             precision    recall  f1-score   support

   negative       0.83      0.79      0.81       408
   positive       0.81      0.84      0.82       417

avg / total       0.82      0.82      0.82       825

